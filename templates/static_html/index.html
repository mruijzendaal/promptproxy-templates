<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="UTF-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>PromptProxy: HTML example</title>
    <link
      rel="icon"
      type="image/svg+xml"
      href="https://prompt-proxy.com/favicon.svg"
    />

    <script src="https://cdn.jsdelivr.net/npm/@tailwindcss/browser@4"></script>
    <style type="text/tailwindcss">
      /* Any custom classes */
    </style>
  </head>
  <body class="min-h-screen flex items-center justify-center bg-stone-100">
    <div class="p-8 w-full max-w-xl">
      <img
        src="https://prompt-proxy.com/logo_text.svg"
        alt="PromptProxy Logo"
        class="mx-auto h-32 w-auto mb-4"
        width="240"
        height="48"
      />
      <h1 class="text-5xl font-bold text-gray-900">PromptProxy example</h1>
      <h2 class="text-3xl font-bold text-gray-500 mb-6">Plain HTML</h2>

      <form id="chat-form" class="space-y-4">
        <div>
          <label class="block text-gray-700 font-medium" for="api-key"
            >PromptProxy API Key</label
          >
          <p class="mb-2 text-gray-500">
            To use this in your own plain HTML page, you would hardcode this API
            key there. This is safe to do: You set rate-limits, token-limits,
            model restrictions, and endpoint rules in our UI.
            <br class="mb-2" />
            <br class="mb-2" />
            Get your key at
            <a
              href="https://prompt-proxy.com"
              class="text-blue-600 hover:underline"
              >prompt-proxy.com</a
            >.
          </p>
          <input
            id="api-key"
            type="password"
            required
            placeholder="Get your PromptProxy "
            class="w-full px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 bg-gray-50"
          />
        </div>
        <div>
          <label class="block text-gray-700 font-medium" for="prompt"
            >Prompt</label
          >
          <p class="text-gray-500 mb-2">
            To use this in your own plain HTML page, you could hardcode your own
            prompt, or have some dynamic user input.
          </p>
          <textarea
            id="prompt"
            required
            rows="3"
            placeholder="Type your prompt here..."
            class="w-full px-4 py-2 border rounded-lg focus:outline-none focus:ring-2 focus:ring-blue-500 bg-gray-50"
          ></textarea>
        </div>
        <button
          id="submit-btn"
          type="submit"
          class="w-full py-2 px-4 bg-blue-600 text-white font-semibold rounded-lg hover:bg-blue-700 transition disabled:bg-blue-200"
        >
          Submit
        </button>
      </form>
      <div id="response-container" class="mt-6">
        <label class="block text-gray-700 font-medium mb-1">Response</label>
        <pre
          id="response"
          class="border w-full min-h-[100px] p-4 bg-gray-100 rounded-lg text-gray-800 whitespace-pre-wrap"
        ></pre>
      </div>
    </div>
    <script>
      const form = document.getElementById("chat-form");
      const responseField = document.getElementById("response");
      const apiInput = document.getElementById("api-key");
      const promptInput = document.getElementById("prompt");
      const submitBtn = document.getElementById("submit-btn");

      function updateSubmitVisibility() {
        const apiVal = apiInput.value.trim();
        const promptVal = promptInput.value.trim();
        submitBtn.disabled = !(apiVal && promptVal);
      }

      apiInput.addEventListener("input", updateSubmitVisibility);
      promptInput.addEventListener("input", updateSubmitVisibility);
      // Initial state
      updateSubmitVisibility();

      form.addEventListener("submit", async (e) => {
        e.preventDefault();
        responseField.textContent = "Loading...";
        const apiKey = apiInput.value.trim();
        const prompt = promptInput.value.trim();
        try {
          const res = await fetch(
            // Normally, you would use the OpenAI endpoint directly:
            // "http://api.openai.com/v1/chat/completions",
            // Replacing it with PromptProxy endpoint, giving you control over
            // rate-limits, token-limits, and endpoint rules.
            "https://api.prompt-proxy.com/v1/chat/completions",
            {
              method: "POST",
              headers: {
                "Content-Type": "application/json",
                Authorization: `Bearer ${apiKey}`,
              },
              body: JSON.stringify({
                model: "gpt-3.5-turbo",
                messages: [{ role: "user", content: prompt }],
                temperature: 0.7,
              }),
            }
          );
          if (!res.ok) {
            const error = await res.json();
            throw new Error(
(error.error?.message || error?.message || "API Error") +
                " (" +
                res.status +
                ")"
);
          }
          const data = await res.json();
          responseField.textContent =
            data.choices?.[0]?.message?.content || "[No response]";
        } catch (err) {
          responseField.textContent = "Error: " + err.message;
        }
      });
    </script>
  </body>
</html>
